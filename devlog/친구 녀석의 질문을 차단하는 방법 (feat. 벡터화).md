# 친구 녀석의 질문을 차단하는 방법 (feat. 벡터화)
## 기획 및 구성

친구와 텔레그램으로 주로 소통을 하고 있다. 이 녀석은 내가 연락하는 몇 안 되는 친구이지만 요즘 따라 자꾸만 내게 뭐하냐는 질문 세례를 날린다. 제 딴에는 내게 관심을 주고, 또 현재 내가 개발자로서 전직을 준비하고 있기에 이미 개발자로 일하고 있는 입장에서 도움을 주기 위함일 수도 있지만 연속된 질문은 나를 피곤하게 하는 데 충분했다. 그래서 친구가 보낸 텔레그램 메시지에서 '뭐하냐'는 의미가 담긴 메시지를 필터링하면 어떨까라는 생각에 아주 작은 프로젝트를 기획 및 만들게 됐다.

다행히 텔레그램은 여러 가지의 사용자 API를 제공해주기에 웹훅으로 설정만 해주면 메시지를 설정한 웹훅 서버로 보내주는 기능을 제공해주었기에 해당 기능을 사용했다. 이제 문제는 '뭐하냐'는 뉘앙스를 담긴 메시지를 필터링하는 것인데 이게 생각보다 간단치 않았다. '뭐해' ,'모해', 'ㅁㅎ' 같은 여러 Seed 데이터를 사전에 구비한 후 해당 텍스트들이 메시지에 포함되어 있는지 확인하는 건 비효율적이었고 또한 같은 의미지만 단어 변형이 많은 한국어 특성상 cache hit가 낮게 나타나는 문제가 있었다.

두 번째로 고려한 방법은 LLM을 활용하는 것이다. 사실 이 방법이 working 한다면 너무나 쉽게 문제를 해결할 수 있다. 이미 LLM은 한국어의 의미 유사도를 그 무엇보다 잘 판단하기에 간단하게 Gemini를 붙여서 채팅에 대한 의미 유사도를 판단한 후 필터링을 진행했지만 이 방법의 문제는 너무 느리다는 것이었다. API 방식으로 Gemini에게 쿼리를 날리고 응답받기까지 그 시간이 너무 오래 걸렸다. 채팅의 특성상 삘(Feel)을 받으면(?) 초당 전송하는 메시지가 여러 건인데, Gemini까지 타고 응답을 받을 때 즈음이면 '뭐하냐'는 메시지는 이미 채팅창 상단으로 옮겨져 친구에게 적절한 주의(?) 메시지를 타이밍 맞게 보낼 수가 없었다. 그렇기에 이 방법도 탈락.

마지막 방법은 직접 의미의 유사도를 판단하는 시스템을 구축하는 것이다. LLM도 사실 본질적으로 이 방법을 사용하는 것으로 알고 있는데 LLM에 비해 정밀도는 다소 떨어지지만 빠른 속도를 위해 해당 방법을 택했다. 의미의 유사도를 판단하는 방법은 사전에 '뭐하냐' '모해', '뭐함', 'ㅁㅎ' 같은 비슷한 의미를 가진 표현들을 사전에 벡터화하고 이후 필터링할 메시지 역시 벡터화(이것을 임베딩한다고 표현하는 듯하다)해서 기존 벡터 데이터들과 그 유사도를 비교하고 유사도가 일정 임계치를 넘으면 유사한 의미라고 판단하는 것이다. 기본적인 워크플로우는 다음과 같다.

1. '뭐하냐'는 의미를 담은 여러 단어를 사전에 벡터화한다. ['뭐하냐', '모함', '뭐행', '친구야 뭐해?'... etc ]    
2. 채팅 데이터를 임베딩해서 벡터로 변환한 다음 기존에 벡터화한 Seed 데이터와 유사도를 비교한다.
3. 유사도가 일정 임계치를 넘으면 같은 의미라고 판단한다.

**'모해'라는 표현을 벡터화한 예**

![](https://postfiles.pstatic.net/MjAyNTA4MTVfMjk1/MDAxNzU1MjMzNzUwNDQ1.LL4yJNwgkrhQbHoN32CGk_Awg2w4WHmVQfwPTPlDWowg.wliDthSc2I3WGdsTTbaFhlIEah6ht8VkHVWhyXTHtPUg.PNG/image.png?type=w773)

​

위 프로젝트에서는 임베딩한 데이터, 즉 벡터를 저장해야 했기에 해당 자료형을 지원하는 Elasticsearch를 사용했다. 요즘 벡터DB 사용이 많아져 여러 핫한 벡터DB가 많지만 비교적 익숙한 Elasticsearch를 사용했다. 또한, 최대한 빠르게 만드는 게 목표였기에 경량화된 프레임워크인 Flask를 사용했다.

---
​

## 문제점

이번 프로젝트를 진행하면서 벡터와 임베딩에 대한 배경지식이 거의 없다 보니, 임베딩이 무엇이고 이를 통해 어떻게 의미 유사도를 판단하는지 이해하는 데 꽤 시간을 썼다. 텍스트를 벡터로 바꾸려면 임베딩 모델이 필요한데, 다행히 이미 잘 만들어진 모델들이 많아 그중 적합한 것을 선택해서 사용하면 된다. 나는 한국어 처리에 특화된 'jhgan/ko-sbert-multitask' 모델을 사용했다.

모델을 통해서 임베딩한 것까지는 좋았는데, 로컬 환경과 서버 환경에서 임베딩한 값이 차이가 나는 게 문제였다. 로컬에서 테스트할 때 '친구야 뭐하니?'라는 표현의 의미적 유사도는 0.912313이었는데 서버에서 테스트를 하니 유사도가 0.85123 이런 식으로 떨어져버렸다. CPU가 달라서 그런 건가 싶었지만 CPU가 달러도 그 차이는 극히 미미하다고 Claude형이나 여타 다른 LLM 형님들이 말한 걸로 봐서는 CPU 차이는 아닌 듯했다.

처음에는 단순하게 다음과 같이 코드를 작성했다:

```python
model = SentenceTransformer("jhgan/ko-sbert-multitask").eval()
```

device를 별도로 설정하지 않으면 PyTorch(모델을 활용해 텍스트를 임베딩 해주는 핵심 프레임워크)는 사용 가능한 최적의 디바이스를 자동으로 선택한다. 로컬 환경(M1 Pro)에서는 MPS(Metal Performance Shaders)가 사용 가능했기 때문에 GPU 가속을 통해 임베딩이 진행되었고, 서버 환경에서는 GPU가 아예 없어서 CPU로만 임베딩이 처리된 것이었다.

이 차이가 바로 문제의 핵심이었다. 동일한 모델과 텍스트를 사용했지만, 로컬에서는 MPS를 통한 GPU 연산으로, 서버에서는 CPU 연산으로 처리되면서 부동소수점 연산 방식의 차이가 발생했다. 그 결과 '친구야 뭐하니?' 표현의 의미적 유사도가 로컬에서는 0.912313, 서버에서는 0.85123으로 상당한 차이를 보인 것이다.

이 문제를 해결하기 위해 나중에 다음과 같이 device를 명시적으로 CPU로 고정했다:
```python
model = SentenceTransformer("jhgan/ko-sbert-multitask", device="cpu").eval()
```

이렇게 하면 로컬과 서버 모두 동일하게 CPU 연산을 사용하게 되어 임베딩 결과의 일관성을 보장할 수 있게 되었다.

(Pytorch가 무엇이고 MPS가 무엇인지는 나도 지금 공부 중에 있으므로 여기서는 생략)

​
## 결론

친구의 귀찮은 질문을 걸러내려고 시작한 프로젝트였는데, 임베딩과 벡터DB를 새롭게 배우는 좋은 기회가 되었다. 그러나 해보니까 완벽하지는 않은 듯하다. 이를테면 단순히 '뭐해' 같은 단어를 앞에 배치하거나 문장의 길이가 짧은 표현에 대해서는 의미적 유사도를 잘 필터링해주지만, 문장이 길거나 '뭐하냐'는 표현이 문장 후미에 등장하면 정확성이 많이 떨어진다.

아마 이 부분이 AI에서 데이터가 중요하다고 하는 병목이 아닐까 한다. 나 같은 경우는 시드 데이터를 많이 넣지 않았기에 벡터들 간의 거리 계산에서 미묘한 뉘앙스를 제대로 캐치하지 못하는 것 같다. 특히 한국어의 경우 어순이 자유롭고 문맥에 따라 의미가 달라지는 경우가 많은데, 이런 언어적 특성을 충분히 반영하려면 훨씬 더 다양하고 풍부한 데이터셋이 필요할 것이다.

결국 '쓰레기가 들어가면 쓰레기가 나온다(Garbage In, Garbage Out)'는 말처럼, 아무리 좋은 임베딩 모델을 사용해도 입력 데이터의 질과 양이 부족하면 한계가 명확하다는 것을 실감했다.

​

​

ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ

![](https://postfiles.pstatic.net/MjAyNTA4MTVfODEg/MDAxNzU1MjM1NTY0Njgz.nnjDt91u66C51u6Is9GzNUOBZ_5-hjQLjpO0F-kalkYg.bcCBkMpPdyUw5TL0bvSW1z-Fy0A1E0xmGByxE-L4igcg.PNG/image.png?type=w773)

---

**전체 n8n 워크플로우 (메시지 의미 분석뿐 아니라 여러 다른 플로우도 포함되어 있음)**

![](https://postfiles.pstatic.net/MjAyNTA4MTVfMjkx/MDAxNzU1MjMyODAwNTk1.DPoIfaeyZghPAF4-yoFvL8rJw9-izoK3RHWF56qCxB4g.lCmMwb2lh7WBJgOL1iJbpAWeNn9lKqSonWDD4hp1IjEg.PNG/image.png?type=w773)

​