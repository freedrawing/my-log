# Git commit message template

✨ :sparkles: 새로운 기능 추가, 구현 | ✨feat : Introduce new features
🐛 :bug: 버그 수정 | 🐛 fix : Fix a bug
🚑 :ambulance: 긴급 수정 | 🚑 fix : Critical hotfix
🔒 :lock: 보안 이슈 수정 | 🔒 fix : Fix security issues
🔥 :fire: 삭제(파일, 코드) | 🔥 remove : Remove code or files
🚛 :truck: 파일, 경로, route를 옮기거나 이름 변경 | 🚛 update : Move or rename resources
📝 :memo: 문서 파일 추가/수정 | 📝 update : Add or update documentation
💡 :bulb: 주석 추가/수정 | 💡 update : Add or update comments in source code
🧹 :broom: 단순오타 수정, 잡동사니 처리 | 🧹 chore : Modify typo
⚡ :zap: 성능 개선 | ⚡ perf : Improve performance
🎨 :art: 코드 구조/형태 개선 | 🎨 perf : Improve structure / format of the code
♻️ :recycle: 코드 리팩토링 | ♻️ refactor : Refactor code
👽 :alien: 외부 API 변화로 인한 수정 | 👽 update : Update code due to external API changes
🗃️ :card_file_box: 데이터베이스 관련 수정 | 🗃️ update : Perform database related changes
🙈 :see-no-evil: gitignore 추가/수정 | 🙈 update : Add or update a .gitignore file

---

# 질문

---

# 해야 할 것

* github action으로 test할 때, 어떤 테스트 메서드가 실행되었는지, 그리고 해당 테스트가 성공했는지 실패했는지 로그로 알 수 없을까.
* API가 만들어져 있지 않은 URL로 호출시 기본적으로 토큰 검사를 한다. 이런 경우, 잘못된 요청이라는 예외가 더 적절할 것 같다.
* 엘라스틱 서치도 적용할 수 있을까? 그전에 엘라스틱 서치란 무엇인가?
* B+tree와 B-tree의 차이점은 뭘까?
	* B+tree에서 'Like%'는 인덱스 사용이 가능하지만, '%Like'는 사용이 불가하다는 건 과연 무슨 의미?
* CDN 해보기.
* README
	* 아키텍쳐 구조 명시
	* Trouble Shooting
	* Ngrinder 
		* 성능 개선이 드라마틱하지 않아도 된다.
	* 테스트 코드나 이런 거 시각적인 자료
* v2 API like 성능 향상을 해보자.
* RediSearch
	* HashOpertations<K, HK, HV> <- 왜 반드시 String으로 Serialize해야만 데이터가 들어갈까. 이상하네... Config에서 Jackson으로 설정해줘서 괜찮을 줄 알았는데....
* 로컬 캐시는 어떻게 확인하지? 캐시 메트릭?
* @Cacheable top=100 넘기는 로직 마음에 안 듦.
* @Cacheable viewCount 해결해야 함
* @Transactional(readOnly = true) -> @Transactional(propagation = Propagation.REQUIRES_NEW) 갈 수 있는 방법은 없나...
* 랭킹 시스템 동시성 이슈에 대해 생각해보자. -> 캐시 메모리에서는 동시성 발생 이슈가 없을까?
* Message-Queue 방식으로 생각
* 

---
# Keyword
spring cloud vault
하쉬코프(HashiCorp) - vault
스프링-stop

아파치 - 제이미터 -> 동시성 제어 툴
NGrinder 

동시성
* 하나의 데이터를 가지고 여러 스레드에서 동시다발적으로 접근했을 때, 최신 데이터와 현재 데이터의 싱크가 맞지 않아서 발생하는 문제.
	* 낙관적 락
	* 비관적 락
	* 분산 락
* 동시성 제어는 만능이 아니다.
* 동시성이 종종 발생했을 때와 매일 발생했을 때 걸어야 하는 락이 다르다.
* 함수형 분산락 공부

인덱스
* 인덱스를 걸려면 어디에 걸어야 하는가.
* 인덱스는 만능인가? 인덱스에 단점이 있으면 어떤 상황에서만 인덱스를 사용해야 하는가
* 복합 인덱스는 한 개 이상의 컬럼을 엮어서 인덱스를 거는 건데, 복합 인덱스를 걸 때, 순서에 따라서는 어떻게 동작을 하는가
* 시간 차이 검증
* 복합 인덱스는 무조건 타는가?
* 인덱스 자료구조도 알아야 한다.
* 인덱스 분포도 <- 검색

쿼리 튜닝
* 스트레이트 조인
* 조인을 5개 한다고 하면, 조인 순서에 따라 성능이 달라진다.

캐싱
* 캐싱 전략
* Spring Cache
* Redis Cache
* 스프링 캐시가 더 빠를까?
* 레디스 캐시도 쥬디스와 레튜스가 있는데 레튜스만 캐시 매니저가 있음.
	* CrudRepository는 잘 사용하지 않음.
	* RedisTemplate이 권장됨.
	* RediSearch
	* CacheManager -> @Cacheable
	* RedisTemplate을 사용했을 때와 @Cacheable을 사용했을 때의 차이
* 로컬 캐시를 사용했을 때 문제
* 'RediSearch'보다는 ElasticSearch 사용할 것
* 레디스에 데이터를 Write할 때도 Transaction 처리를 해야 할까?
* Scan 명령어로는 필터링이 안 되는가? Scan 명령어를 조금 더 자세히 알아보자.

배포
* 롤링, 까나리, 블루그린


---
일반 리스트로 인기 쇼핑몰을 처리하니 `@Cacheable` 을 사용할 수 있으나 리스트 단위로 처리를 하다보니까, `@CachePut`이나 `@CacheEvict`은 사용하기가 쉽지 않다. 또한, 순위 변동이 있을 때도 업데이트를 하려면 리스트 타입이라 엘리먼트 하나하나를 옮겨야 하기에 불편함이 있다. 그렇기에 엘리먼트를 전부 옮기려면 `O(N)`만큼 시간이 걸린다.

이 문제를 @SortedSet으로 해결해보자.
































안녕하세요, 이번 테스트에서는 **조회수를 기준으로 인기 쇼핑몰 랭킹을 조회하는 API의 성능을 비교**해보겠습니다.  **DB 조회 → 캐싱 적용 → 실시간성을 고려한 캐싱 방식** 이렇게 3단계 구성했고요. 단계별로 진행해보겠습니다.

**📌 Step 1: DB에서 직접 조회**
💡 **먼저, 가장 기본적인 방식으로 DB에서 인기 쇼핑몰 랭킹을 조회하는 방법입니다.**
 
• 조회수를 기준으로 **상위 100개 쇼핑몰 데이터를 가져오도록 구현을 했구요.
• **실시간 데이터를 조회할 수 있다는 장점**이 있지만,
• **조회 속도가 상대적으로 느린 것이 단점**입니다.

**📌 Step 2: Redis 캐싱 적용**
💡 **다음은 캐싱을 적용한 방식입니다.**
• **(빨라진 속도 보여주면서) 상위 100개의 쇼핑몰 데이터를 Redis에 캐싱하여 응답 속도를 향상**시켰습니다. 
• **DB를 직접 조회하지 않고 Redis에서 데이터를 가져오므로 속도가 빠르지만 실시간성을 떨어진다는 단점이 있습니다. 실시간성을 확보하기 위해 TTL을 짧게 설정하면 만료시마다 DB 호출이 발생하기에 캐싱의 장점이 다소 희석될 수 있습니다.**

📌 Step 3: 조회수 증가 메커니즘
조회수 같은 경우에는 특정 쇼핑몰을 조회하는 API를 호출하면 증가하게 설정했습니다. 다만, 어뷰징 방지를 위해 해당 유저의 IP와 쇼핑몰 ID를 키값으로 레디스에 5분 동안 캐싱해 놓고, 해당 조회 이력이 캐시 데이터 존재하면 조회수가 증가하지 않게끔 설정했습니다.

📌 Step 4: 동시성 문제
다만 조회수를 증가시킬 때 동시성 문제가 발생할 수 있습니다. 이 부분은 이후 설명에서 추가적으로 말씀드리겠습니다.

📌 V2
마지막은 실시간성을 고려한 캐싱 방식입니다. 기존 방식에서는 레디스가 데이터를 임시 저장해놓는 용도였다면, 마지막 방식에서는 레디스에 저장된 데이터를 최신 데이터라고 간주하고 10분만다 DB에 업데이트 되도록 구현했습니다. 

현재는 정렬이 된 데이터를 리스트로 저장해놓았지만, 랭킹을 바뀌거나 순위권에서 밀려났을 때 해당 데이터를 변경해줌과 동시에 데이터 순서를 바꿔줘야 하는 비효율이 발생합니다. 또한, 기존과 다르게 레디스에 저장된 정보가 가장 최신의 데이터라고 간주하다보니, 랭킹에 없는 쇼핑몰이 조회됐을 때도 캐시 데이터에 포함시킨 후 10분마다 업데이트 할 때 반영해줘야 하기에 상위 쇼핑몰 뿐만 아니라 10분 안에 조회된 모든 쇼핑몰 데이터를 레디스에 포함시켜야 합니다.



그렇기에 Redis에서 제공하는 **Sorted Set** 자료구조를 활용했습니다. **Sorted Set**은 **데이터 변경이 발생할 때마다 자동으로 정렬되는 기능을 제공**하므로, **별도로 순서를 조정할 필요가 없다는 장점**이 있습니다.

(Sorted Set 보여주며) 지금 보시는 자료구조가 Sorted Set인데 Score라는 값이 Sorted Set이 정렬을 하는 기준으로 사용하는 값입니다. 본 프로젝트에서는 조회수를 Score 값으로 활용해 랭킹을 관리했습니다.

다만 Sorted Set은 이름에서 알 수 있는 것처럼 Set의 특성상 Member에는 쇼핑몰 키값이 들어가야 Set의 이점인 빠른 조회가 가능합니다. 그렇기에 쇼핑몰 정보를 담은 객체를 Member에 넣으면 Set의 이점을 살릴 수 없기에 Sorted Set에는 쇼핑몰 ID만 저장하고 쇼핑몰 상세 정보는 별도의 Hash에 저장했습니다. 이렇게 구조를 이중화함으로써 정렬을 자동으로 수행하면서도 조회시 발생하는 속도를 O(1)으로 최적화했습니다.


📌 벌크 업데이트 및 레디스의 싱글 스레드
마지막으로 레디스에 있는 데이터를 DB로 보내는 작업인데요. 스프링에서 제공하는 스케줄러 기능을 이용해 10분마다 DB에 캐시에 저장된 변경 사항을 벌크로 업데이트하게끔 구현했습니다.

다만 현재 방식에서는 Redis를 메인 저장소로 사용하고 있는 만큼 DB가 데이터를 저장하는 저장소라기보다는 백업 용도가 강하기 때문에 캐싱이라고 하기 어려운 측면이 있는 것 같습니다. 

그러나 이전 방식에서는 서로 다른 유저가 접근했을 때 조회수 업데이트로 인한 동시성 문제가 발생할 수 있으나 레디스는 싱글 스레드 기반의 데이터베이스고, 특정 엘리먼트의 업데이트 같은 단일 연산에는 원자성이 보장되기에 스레드 권한을 빼앗길 수 있는 복합 연산이 아닌 현재 시나리오에서는 동시성 문제가 어느 정도 해소된다는 면에서 의미가 있다고 생각합니다.

이상으로 시연 영상 마치겠습니다. 감사합니다.













































































